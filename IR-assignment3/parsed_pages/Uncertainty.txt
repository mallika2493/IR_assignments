uncertainty - wikipedia
uncertainty is a situation which involves imperfect and or unknown information however  uncertainty is an unintelligible expression without a straightforward description  it arises in subtly different ways in a number of fields including insurance philosophy physics statistics economics finance psychology sociology engineering metrology and information science it applies to predictions of future events to physical measurements that are already made or to the unknown uncertainty arises in partially observable and or stochastic environments as well as due to ignorance and or indolence


concepts
although the terms are used in various ways among the general public many specialists in decision theory statistics and other quantitative fields have defined uncertainty risk and their measurement as 
in economics frank knight distinguished risk and uncertainty  uncertainty being risk that is immeasurable not possible to calculate and referred to as knightian uncertainty 
there are other taxonomies of uncertainties and decisions that include a broader sense of uncertainty and how it should be approached from an ethics perspective 
for example if it is unknown whether or not it will rain tomorrow then there is a state of uncertainty if probabilities are applied to the possible outcomes using weather forecasts or even just a calibrated probability assessment the uncertainty has been quantified suppose it is quantified as a 90  chance of sunshine if there is a major costly outdoor event planned for tomorrow then there is a risk since there is a 10  chance of rain and rain would be undesirable furthermore if this is a business event and  100,000 would be lost if it rains then the risk has been quantified  a 10  chance of losing  100,000  these situations can be made even more realistic by quantifying light rain vs heavy rain the cost of delays vs outright cancellation etc
some may represent the risk in this example as the  expected opportunity loss   eol  or the chance of the loss multiplied by the amount of the loss  10     100,000    10,000  that is useful if the organizer of the event is  risk neutral  which most people are not most would be willing to pay a premium to avoid the loss an insurance company for example would compute an eol as a minimum for any insurance coverage then add onto that other operating costs and profit since many people are willing to buy insurance for many reasons then clearly the eol alone is not the perceived value of avoiding the risk
quantitative uses of the terms uncertainty and risk are fairly consistent from fields such as probability theory actuarial science and information theory some also create new terms without substantially changing the definitions of uncertainty or risk for example surprisal is a variation on uncertainty sometimes used in information theory but outside of the more mathematical uses of the term usage may vary widely in cognitive psychology uncertainty can be real or just a matter of perception such as expectations threats etc
vagueness or ambiguity are sometimes described as  second order uncertainty  where there is uncertainty even about the definitions of uncertain states or outcomes the difference here is that this uncertainty is about the human definitions and concepts not an objective fact of nature it is usually modelled by some variation on zadeh s fuzzy logic it has been argued that ambiguity however is always avoidable while uncertainty  of the  first order  kind  is not necessarily avoidable
uncertainty may be purely a consequence of a lack of knowledge of obtainable facts that is there may be uncertainty about whether a new rocket design will work but this uncertainty can be removed with further analysis and experimentation at the subatomic level however uncertainty may be a fundamental and unavoidable property of the universe in quantum mechanics the heisenberg uncertainty principle puts limits on how much an observer can ever know about the position and velocity of a particle this may not just be ignorance of potentially obtainable facts but that there is no fact to be found there is some controversy in physics as to whether such uncertainty is an irreducible property of nature or if there are  hidden variables  that would describe the state of a particle even more exactly than heisenberg s uncertainty principle allows
measurements
the most commonly used procedure for calculating measurement uncertainty is described in the  guide to the expression of uncertainty in measurement   gum  published by iso a derived work is for example the national institute for standards and technology  nist  technical note 1297  guidelines for evaluating and expressing the uncertainty of nist measurement results  and the eurachem citac publication  quantifying uncertainty in analytical measurement  the uncertainty of the result of a measurement generally consists of several components the components are regarded as random variables and may be grouped into two categories according to the method used to estimate their numerical values 
by propagating the variances of the components through a function relating the components to the measurement result the combined measurement uncertainty is given as the square root of the resulting variance the simplest form is the standard deviation of a repeated observation
in metrology physics and engineering the uncertainty or margin of error of a measurement when explicitly stated is given by a range of values likely to enclose the true value this may be denoted by error bars on a graph or by the following notations 
in the last notation parentheses are the concise notation for the   notation for example applying 10  1 2 meters in a scientific or engineering application it could be written 7001105000000000000 10.5 m or 7001105000000000000 10.50 m by convention meaning accurate to within one tenth of a meter or one hundredth the precision is symmetric around the last digit in this case its half a tenth up and half a tenth down so 10.5 means between 10.45 and 10.55 thus it is understood that 10.5 means 7001105000000000000 10.5 0.05 and 10.50 means 7001105000000000000 10.50 0.005 also written 7001105000000000000 10.50 5  and 7001105000000000000 10.500 5  respectively but if the accuracy is within two tenths the uncertainty is   one tenth and it is required to be explicit  7001105000000000000 10.5 0.1 and 7001105000000000000 10.50 0.01 or 7001105000000000000 10.5 1  and 7001105000000000000 10.50 1  the numbers in parenthesis apply to the numeral left of themselves and are not part of that number but part of a notation of uncertainty they apply to the least significant digits for instance 7000100794000000000 1.00794 7  stands for 7000100794000000000 1.00794 0.00007 while 7000100794000000000 1.00794 72  stands for 7000100794000000000 1.00794 0.00072 this concise notation is used for example by iupac in stating the atomic mass of elements
the middle notation is used when the error is not symmetrical about the value   for example 7000340000000000000 3.4 0.3
 0.2 this can occur when using a logarithmic scale for example
often the uncertainty of a measurement is found by repeating the measurement enough times to get a good estimate of the standard deviation of the values then any single value has an uncertainty equal to the standard deviation however if the values are averaged then the mean measurement value has a much smaller uncertainty equal to the standard error of the mean which is the standard deviation divided by the square root of the number of measurements this procedure neglects systematic errors however
when the uncertainty represents the standard error of the measurement then about 68.3  of the time the true value of the measured quantity falls within the stated uncertainty range for example it is likely that for 31.7  of the atomic mass values given on the list of elements by atomic mass the true value lies outside of the stated range if the width of the interval is doubled then probably only 4.6  of the true values lie outside the doubled interval and if the width is tripled probably only 0.3  lie outside these values follow from the properties of the normal distribution and they apply only if the measurement process produces normally distributed errors in that case the quoted standard errors are easily converted to 68.3    one sigma   95.4    two sigma   or 99.7    three sigma   confidence intervals
in this context uncertainty depends on both the accuracy and precision of the measurement instrument the lower the accuracy and precision of an instrument the larger the measurement uncertainty is notice that precision is often determined as the standard deviation of the repeated measures of a given value namely using the same method described above to assess measurement uncertainty however this method is correct only when the instrument is accurate when it is inaccurate the uncertainty is larger than the standard deviation of the repeated measures and it appears evident that the uncertainty does not depend only on instrumental precision
uncertainty and the media
uncertainty in science and science in general is often interpreted much differently in the public sphere than in the scientific community this is due in part to the diversity of the public audience and the tendency for scientists to misunderstand lay audiences and therefore not communicate ideas clearly and effectively one example is explained by the information deficit model also in the public realm there are often many scientific voices giving input on a single topic for example depending on how an issue is reported in the public sphere discrepancies between outcomes of multiple scientific studies due to methodological differences could be interpreted by the public as a lack of consensus in a situation where a consensus does in fact exist this interpretation may have even been intentionally promoted as scientific uncertainty may be managed to reach certain goals for example global warming contrarian activists took the advice of frank luntz to frame global warming as an issue of scientific uncertainty which was a precursor to the conflict frame used by journalists when reporting the issue
 indeterminacy can be loosely said to apply to situations in which not all the parameters of the system and their interactions are fully known whereas ignorance refers to situations in which it is not known what is not known  these unknowns indeterminacy and ignorance that exist in science are often  transformed  into uncertainty when reported to the public in order to make issues more manageable since scientific indeterminacy and ignorance are difficult concepts for scientists to convey without losing credibility conversely uncertainty is often interpreted by the public as ignorance the transformation of indeterminacy and ignorance into uncertainty may be related to the public s misinterpretation of uncertainty as ignorance
journalists often either inflate uncertainty  making the science seem more uncertain than it really is  or downplay uncertainty  making the science seem more certain than it really is  one way that journalists inflate uncertainty is by describing new research that contradicts past research without providing context for the change other times journalists give scientists with minority views equal weight as scientists with majority views without adequately describing or explaining the state of scientific consensus on the issue in the same vein journalists often give non-scientists the same amount of attention and importance as scientists
journalists may downplay uncertainty by eliminating  scientists  carefully chosen tentative wording and by losing these caveats the information is skewed and presented as more certain and conclusive than it really is  also stories with a single source or without any context of previous research mean that the subject at hand is presented as more definitive and certain than it is in reality there is often a  product over process  approach to science journalism that aids too in the downplaying of uncertainty finally and most notably for this investigation when science is framed by journalists as a triumphant quest uncertainty is erroneously framed as  reducible and resolvable 
some media routines and organizational factors affect the overstatement of uncertainty  other media routines and organizational factors help inflate the certainty of an issue because the general public  in the united states  generally trusts scientists when science stories are covered without alarm-raising cues from special interest organizations  religious groups environmental organization political factions etc  they are often covered in a business related sense in an economic-development frame or a social progress frame the nature of these frames is to downplay or eliminate uncertainty so when economic and scientific promise are focused on early in the issue cycle as has happened with coverage of plant biotechnology and nanotechnology in the united states the matter in question seems more definitive and certain
sometimes too stockholders owners or advertising will pressure a media organization to promote the business aspects of a scientific issue and therefore any uncertainty claims that may compromise the business interests are downplayed or eliminated
applications
see also
references
further reading
external links
